{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acae95fb-3f90-4dca-8d3f-de7d80a2ecdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siavash/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"celadro_3D_scripts_final/plot/\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import plot\n",
    "import archive\n",
    "import animation\n",
    "import gc\n",
    "import zlib\n",
    "from sklearn.metrics import mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "381b47b9-74d4-40cc-be6d-215632806c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = archive.loadarchive('mpress-full')\n",
    "xsec = 8\n",
    "max_delta = 50\n",
    "N = 121"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7513b8f9-317a-44ec-9d9c-3caa0e0d44be",
   "metadata": {},
   "source": [
    "### Plot Kolmogorov Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c946652e-6795-45a6-9e0c-a2afef05d167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_kolmogorov_complexity(field):\n",
    "    field = field.ravel()\n",
    "    byte_string = str(field).encode('utf-8')\n",
    "    compressed_data = zlib.compress(byte_string)\n",
    "    return len(compressed_data)\n",
    "\n",
    "def get_isotropic_stress(frame):\n",
    "    sxx = frame.field_sxx\n",
    "    sxx = np.reshape(sxx,(frame.parameters['Size'][2],frame.parameters['Size'][0],frame.parameters['Size'][1]))\n",
    "    syy = frame.field_syy\n",
    "    syy = np.reshape(syy,(frame.parameters['Size'][2],frame.parameters['Size'][0],frame.parameters['Size'][1]))\n",
    "    szz = frame.field_szz\n",
    "    szz = np.reshape(szz,(frame.parameters['Size'][2],frame.parameters['Size'][0],frame.parameters['Size'][1]))\n",
    "    p = (1/3)*(sxx+syy+szz)\n",
    "    p = p[xsec,:,:]\n",
    "    return p\n",
    "    \n",
    "def measure_kc_ratio_over_deltas(ar,N,xsec,max_delta=50):\n",
    "    avg_kc_ratio = []\n",
    "    var_kc_ratio = []\n",
    "    for i in range(max_delta): \n",
    "        kc_ratios = []\n",
    "        for j in range(N-i-1):\n",
    "            field_j = ar.read_frame(j)\n",
    "            p_j = get_isotropic_stress(field_j)\n",
    "            field_ij = ar.read_frame(j+i)\n",
    "            p_ij = get_isotropic_stress(field_ij)\n",
    "            kc_j = approximate_kolmogorov_complexity(p_j)\n",
    "            kc_ij = approximate_kolmogorov_complexity(p_ij)\n",
    "            kc_ratio = kc_ij/kc_j\n",
    "            kc_ratios.append(kc_ratio)\n",
    "            '''\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))  # Create a figure with two subplots\n",
    "            im1 = ax1.imshow(p_j, interpolation='lanczos', cmap='jet', origin='lower')\n",
    "            fig.colorbar(im1, ax=ax1, orientation='horizontal')\n",
    "            im2 = ax2.imshow(p_ij, interpolation='lanczos', cmap='jet', origin='lower')\n",
    "            fig.colorbar(im2, ax=ax2, orientation='horizontal')\n",
    "            plt.show()\n",
    "            '''\n",
    "        avg_kc_ratio.append(np.mean(kc_ratios))\n",
    "        var_kc_ratio.append(np.var(kc_ratios))\n",
    "        print('done computing delta: ',i)\n",
    "    return range(1,max_delta),avg_kc_ratio,var_kc_ratio\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25faec2f-1991-411d-bd09-a3dc1c031de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done computing delta:  25\n",
      "done computing delta:  26\n",
      "done computing delta:  27\n",
      "done computing delta:  28\n",
      "done computing delta:  29\n",
      "done computing delta:  30\n",
      "done computing delta:  31\n",
      "done computing delta:  32\n",
      "done computing delta:  33\n",
      "done computing delta:  34\n",
      "done computing delta:  35\n",
      "done computing delta:  36\n",
      "done computing delta:  37\n",
      "done computing delta:  38\n",
      "done computing delta:  39\n",
      "done computing delta:  40\n",
      "done computing delta:  41\n",
      "done computing delta:  42\n",
      "done computing delta:  43\n",
      "done computing delta:  44\n",
      "done computing delta:  45\n",
      "done computing delta:  46\n",
      "done computing delta:  47\n",
      "done computing delta:  48\n",
      "done computing delta:  49\n"
     ]
    }
   ],
   "source": [
    "time, mean, var = measure_kc_ratio_over_deltas(ar,N,xsec,max_delta)\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.plot(mean)\n",
    "plt.title('mean')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.plot(var)\n",
    "plt.title('var')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c109ae-cbc5-4b37-a5ce-3296779a79ef",
   "metadata": {},
   "source": [
    "### Plot Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "395ded6b-66a7-492f-b0d3-4c030e3efb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(data, nbins=16):\n",
    "    data = data.ravel()\n",
    "    data_min, data_max = np.min(data), np.max(data)\n",
    "    if data_min == data_max:\n",
    "        return np.zeros_like(data, dtype=int)\n",
    "    \n",
    "    bin_edges = np.linspace(data_min, data_max, nbins + 1)\n",
    "    bin_indices = np.digitize(data, bin_edges) - 1\n",
    "    bin_indices = np.clip(bin_indices, 0, nbins-1)\n",
    "    return bin_indices\n",
    "\n",
    "def mutual_info_sklearn(x, y, nbins=16):\n",
    "    x_disc = discretize(x, nbins)\n",
    "    y_disc = discretize(y, nbins)\n",
    "    mi_value = mutual_info_score(x_disc, y_disc)\n",
    "    return mi_value\n",
    "\n",
    "def measure_MI_over_deltas(ar,N,xsec,max_delta=50):\n",
    "    #N = ar._nframes\n",
    "    #N = 604\n",
    "    avg_MI_ratio = []\n",
    "    var_MI_ratio = []\n",
    "    for i in range(1,max_delta): \n",
    "        MIs = []\n",
    "        for j in range(N-i):\n",
    "            field_j = ar.read_frame(j)\n",
    "            p_j = get_isotropic_stress(field_j)\n",
    "            field_ij = ar.read_frame(j+i)\n",
    "            p_ij = get_isotropic_stress(field_ij)\n",
    "            MI = mutual_info_sklearn(p_j,p_ij)\n",
    "            MIs.append(MI)\n",
    "            \n",
    "        avg_MI_ratio.append(np.mean(MIs))\n",
    "        var_MI_ratio.append(np.var(MIs))\n",
    "        print('done computing delta: ',i)\n",
    "    return range(1,max_delta),avg_MI_ratio,var_MI_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fea9d9-dda9-4fb5-9f5a-27402fbfe40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done computing delta:  1\n",
      "done computing delta:  2\n",
      "done computing delta:  3\n",
      "done computing delta:  4\n",
      "done computing delta:  5\n",
      "done computing delta:  6\n",
      "done computing delta:  7\n",
      "done computing delta:  8\n",
      "done computing delta:  9\n",
      "done computing delta:  10\n",
      "done computing delta:  11\n",
      "done computing delta:  12\n",
      "done computing delta:  13\n",
      "done computing delta:  14\n",
      "done computing delta:  15\n",
      "done computing delta:  16\n",
      "done computing delta:  17\n",
      "done computing delta:  18\n",
      "done computing delta:  19\n",
      "done computing delta:  20\n",
      "done computing delta:  21\n",
      "done computing delta:  22\n",
      "done computing delta:  23\n",
      "done computing delta:  24\n",
      "done computing delta:  25\n",
      "done computing delta:  26\n",
      "done computing delta:  27\n",
      "done computing delta:  28\n",
      "done computing delta:  29\n",
      "done computing delta:  30\n",
      "done computing delta:  31\n",
      "done computing delta:  32\n",
      "done computing delta:  33\n",
      "done computing delta:  34\n",
      "done computing delta:  35\n",
      "done computing delta:  36\n",
      "done computing delta:  37\n",
      "done computing delta:  38\n",
      "done computing delta:  39\n",
      "done computing delta:  40\n",
      "done computing delta:  41\n",
      "done computing delta:  42\n"
     ]
    }
   ],
   "source": [
    "time, mean, var = measure_MI_over_deltas(ar,N,xsec,max_delta)\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.plot(mean)\n",
    "plt.title('mean')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "plt.plot(var)\n",
    "plt.title('var')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c9f60a-1c6d-420e-b9c8-0453b25c9955",
   "metadata": {},
   "source": [
    "### Plot Transfer Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639db263-4972-4d69-8a68-4d9b89865c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bba3171-7192-43a8-b8f3-36f6583b7dc3",
   "metadata": {},
   "source": [
    "### Plot Stress Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08684a18-0bce-4f68-8d57-75bfe36c6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.arange(1,ar._nframes+1,1)\n",
    "for i in rng: \n",
    "    #fname = ''\n",
    "    print(i)\n",
    "    frame = ar.read_frame(i)\n",
    "    '''\n",
    "    sxx = frame.field_sxx\n",
    "    sxx = np.reshape(sxx,(frame.parameters['Size'][2],frame.parameters['Size'][0],frame.parameters['Size'][1]))\n",
    "    syy = frame.field_syy\n",
    "    syy = np.reshape(syy,(frame.parameters['Size'][2],frame.parameters['Size'][0],frame.parameters['Size'][1]))\n",
    "    szz = frame.field_szz\n",
    "    szz = np.reshape(szz,(frame.parameters['Size'][2],frame.parameters['Size'][0],frame.parameters['Size'][1]))\n",
    "    p = (1/3)*(sxx+syy+szz)\n",
    "    p = p[xsec,:,:]\n",
    "    '''\n",
    "    '''\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    im = ax.imshow(p[xsec, :, :], interpolation='lanczos', cmap='jet', origin='lower')\n",
    "    plt.colorbar(im, orientation='horizontal')\n",
    "    plt.show()\n",
    "    '''\n",
    "    del frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a8f324-0887-488e-82cb-8d68e5c05fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ar._ninfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce5c001-79f4-4236-abe6-5d0d44e6f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from scipy import ndimage\n",
    "from scipy.stats import entropy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ImprovedInfoAnalyzer:\n",
    "    \"\"\"\n",
    "    Improved information analysis compatible with your archive format\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, archive, get_stress_function):\n",
    "        \"\"\"\n",
    "        archive: your archive object with read_frame method\n",
    "        get_stress_function: your get_isotropic_stress function\n",
    "        \"\"\"\n",
    "        self.archive = archive\n",
    "        self.get_stress = get_stress_function\n",
    "        self.nframes = archive._nframes if hasattr(archive, '_nframes') else None\n",
    "        \n",
    "    def discretize_adaptive(self, data, nbins=16, method='quantile'):\n",
    "        \"\"\"\n",
    "        Improved discretization with multiple methods\n",
    "        \"\"\"\n",
    "        data = np.array(data).ravel()\n",
    "        data = data[np.isfinite(data)]  # Remove NaN/inf\n",
    "        \n",
    "        if len(data) == 0:\n",
    "            return np.array([])\n",
    "        \n",
    "        if np.min(data) == np.max(data):\n",
    "            return np.zeros(len(data), dtype=int)\n",
    "        \n",
    "        if method == 'quantile':\n",
    "            # Use quantiles for better binning\n",
    "            bin_edges = np.quantile(data, np.linspace(0, 1, nbins + 1))\n",
    "            bin_edges = np.unique(bin_edges)  # Remove duplicates\n",
    "            if len(bin_edges) < 2:\n",
    "                return np.zeros(len(data), dtype=int)\n",
    "        elif method == 'kmeans':\n",
    "            # Use k-means for adaptive binning\n",
    "            from sklearn.cluster import KMeans\n",
    "            try:\n",
    "                kmeans = KMeans(n_clusters=min(nbins, len(np.unique(data))), random_state=42)\n",
    "                labels = kmeans.fit_predict(data.reshape(-1, 1))\n",
    "                return labels\n",
    "            except:\n",
    "                # Fall back to linear binning\n",
    "                bin_edges = np.linspace(np.min(data), np.max(data), nbins + 1)\n",
    "        else:  # linear\n",
    "            bin_edges = np.linspace(np.min(data), np.max(data), nbins + 1)\n",
    "        \n",
    "        bin_indices = np.digitize(data, bin_edges) - 1\n",
    "        bin_indices = np.clip(bin_indices, 0, len(bin_edges)-2)\n",
    "        return bin_indices\n",
    "    \n",
    "    def mutual_info_corrected(self, x, y, nbins=16, method='quantile'):\n",
    "        \"\"\"\n",
    "        Corrected mutual information calculation\n",
    "        \"\"\"\n",
    "        if len(x) != len(y):\n",
    "            min_len = min(len(x), len(y))\n",
    "            x, y = x[:min_len], y[:min_len]\n",
    "        \n",
    "        # Remove invalid values\n",
    "        valid_mask = np.isfinite(x) & np.isfinite(y)\n",
    "        x_clean = x[valid_mask]\n",
    "        y_clean = y[valid_mask]\n",
    "        \n",
    "        if len(x_clean) < 10:  # Need minimum samples\n",
    "            return 0.0\n",
    "        \n",
    "        # Discretize\n",
    "        x_disc = self.discretize_adaptive(x_clean, nbins, method)\n",
    "        y_disc = self.discretize_adaptive(y_clean, nbins, method)\n",
    "        \n",
    "        if len(x_disc) == 0 or len(y_disc) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        try:\n",
    "            mi_value = mutual_info_score(x_disc, y_disc)\n",
    "            return mi_value\n",
    "        except:\n",
    "            return 0.0\n",
    "    \n",
    "    def spatial_mutual_information(self, field1, field2, spatial_lags=[(0,0), (1,0), (0,1), (1,1)], nbins=16):\n",
    "        \"\"\"\n",
    "        Calculate MI between fields at different spatial lags\n",
    "        This captures spatial information flow patterns\n",
    "        \"\"\"\n",
    "        spatial_mis = {}\n",
    "        \n",
    "        for lag_x, lag_y in spatial_lags:\n",
    "            if lag_x == 0 and lag_y == 0:\n",
    "                # Direct temporal MI\n",
    "                mi = self.mutual_info_corrected(field1.ravel(), field2.ravel(), nbins)\n",
    "                spatial_mis[(lag_x, lag_y)] = mi\n",
    "            else:\n",
    "                # Spatial lag MI\n",
    "                if field1.shape[0] > lag_y and field1.shape[1] > lag_x:\n",
    "                    region1 = field1[:-lag_y if lag_y > 0 else None, \n",
    "                                   :-lag_x if lag_x > 0 else None]\n",
    "                    region2 = field2[lag_y:, lag_x:]\n",
    "                    \n",
    "                    mi = self.mutual_info_corrected(region1.ravel(), region2.ravel(), nbins)\n",
    "                    spatial_mis[(lag_x, lag_y)] = mi\n",
    "                else:\n",
    "                    spatial_mis[(lag_x, lag_y)] = 0.0\n",
    "        \n",
    "        return spatial_mis\n",
    "    \n",
    "    def measure_MI_over_deltas_improved(self, N, max_delta=50, spatial_lags=[(0,0), (1,0), (0,1)]):\n",
    "        \"\"\"\n",
    "        Improved version of your MI measurement with spatial consideration\n",
    "        \"\"\"\n",
    "        print(\"Computing improved MI over time deltas...\")\n",
    "        \n",
    "        results = {\n",
    "            'time_deltas': list(range(1, max_delta)),\n",
    "            'spatial_mi_stats': {lag: {'mean': [], 'var': []} for lag in spatial_lags},\n",
    "            'total_mi_mean': [],\n",
    "            'total_mi_var': []\n",
    "        }\n",
    "        \n",
    "        for delta in range(1, max_delta):\n",
    "            print(f'Computing delta: {delta}')\n",
    "            \n",
    "            # Store MI values for all spatial lags\n",
    "            delta_mis = {lag: [] for lag in spatial_lags}\n",
    "            \n",
    "            for j in range(N - delta):\n",
    "                # Read frames\n",
    "                field_j = self.archive.read_frame(j)\n",
    "                field_ij = self.archive.read_frame(j + delta)\n",
    "                \n",
    "                # Get stress fields\n",
    "                stress_j = self.get_stress(field_j)\n",
    "                stress_ij = self.get_stress(field_ij)\n",
    "                \n",
    "                # Calculate spatial MI\n",
    "                spatial_mi = self.spatial_mutual_information(\n",
    "                    stress_j, stress_ij, spatial_lags\n",
    "                )\n",
    "                \n",
    "                # Store results\n",
    "                for lag in spatial_lags:\n",
    "                    delta_mis[lag].append(spatial_mi[lag])\n",
    "            \n",
    "            # Compute statistics for each spatial lag\n",
    "            for lag in spatial_lags:\n",
    "                if delta_mis[lag]:\n",
    "                    results['spatial_mi_stats'][lag]['mean'].append(np.mean(delta_mis[lag]))\n",
    "                    results['spatial_mi_stats'][lag]['var'].append(np.var(delta_mis[lag]))\n",
    "                else:\n",
    "                    results['spatial_mi_stats'][lag]['mean'].append(0.0)\n",
    "                    results['spatial_mi_stats'][lag]['var'].append(0.0)\n",
    "            \n",
    "            # Total MI (sum over spatial lags)\n",
    "            total_mis = []\n",
    "            for j in range(len(delta_mis[(0,0)])):\n",
    "                total_mi = sum(delta_mis[lag][j] for lag in spatial_lags)\n",
    "                total_mis.append(total_mi)\n",
    "            \n",
    "            results['total_mi_mean'].append(np.mean(total_mis) if total_mis else 0.0)\n",
    "            results['total_mi_var'].append(np.var(total_mis) if total_mis else 0.0)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def transfer_entropy_frame_sequence(self, frame_indices, spatial_region=None, lag=1, nbins=12):\n",
    "        \"\"\"\n",
    "        Calculate transfer entropy for a sequence of frames\n",
    "        \"\"\"\n",
    "        if len(frame_indices) < lag + 2:\n",
    "            return 0.0\n",
    "        \n",
    "        # Extract time series from frames\n",
    "        time_series = []\n",
    "        for frame_idx in frame_indices:\n",
    "            field = self.archive.read_frame(frame_idx)\n",
    "            stress = self.get_stress(field)\n",
    "            \n",
    "            if spatial_region is not None:\n",
    "                # Extract specific spatial region\n",
    "                y_slice, x_slice = spatial_region\n",
    "                stress_val = np.mean(stress[y_slice, x_slice])\n",
    "            else:\n",
    "                # Use global average\n",
    "                stress_val = np.mean(stress)\n",
    "            \n",
    "            time_series.append(stress_val)\n",
    "        \n",
    "        time_series = np.array(time_series)\n",
    "        \n",
    "        # Calculate transfer entropy (simplified version)\n",
    "        # TE(X->Y) measures info flow from X to Y\n",
    "        return self.transfer_entropy_estimator(time_series, time_series, lag, nbins)\n",
    "    \n",
    "    def transfer_entropy_estimator(self, source_ts, target_ts, lag=1, nbins=12):\n",
    "        \"\"\"\n",
    "        Transfer entropy estimation (from your original request)\n",
    "        \"\"\"\n",
    "        if len(source_ts) != len(target_ts) or len(source_ts) < lag + 2:\n",
    "            return 0.0\n",
    "        \n",
    "        # Prepare variables\n",
    "        y_future = target_ts[lag+1:]\n",
    "        x_past = source_ts[lag:-1]\n",
    "        y_past = target_ts[lag:-1]\n",
    "        \n",
    "        # Remove invalid values\n",
    "        valid_mask = np.isfinite(y_future) & np.isfinite(x_past) & np.isfinite(y_past)\n",
    "        if np.sum(valid_mask) < 10:\n",
    "            return 0.0\n",
    "        \n",
    "        y_future = y_future[valid_mask]\n",
    "        x_past = x_past[valid_mask]\n",
    "        y_past = y_past[valid_mask]\n",
    "        \n",
    "        try:\n",
    "            # Discretize\n",
    "            y_fut_disc = self.discretize_adaptive(y_future, nbins)\n",
    "            x_past_disc = self.discretize_adaptive(x_past, nbins)\n",
    "            y_past_disc = self.discretize_adaptive(y_past, nbins)\n",
    "            \n",
    "            # Calculate conditional mutual information\n",
    "            # TE = I(Y_future; X_past | Y_past)\n",
    "            \n",
    "            # Joint entropies\n",
    "            def joint_entropy(a, b):\n",
    "                ab = a * nbins + b\n",
    "                unique, counts = np.unique(ab, return_counts=True)\n",
    "                p = counts / len(ab)\n",
    "                return -np.sum(p * np.log(p + 1e-10))\n",
    "            \n",
    "            def triple_entropy(a, b, c):\n",
    "                abc = a * nbins**2 + b * nbins + c\n",
    "                unique, counts = np.unique(abc, return_counts=True)\n",
    "                p = counts / len(abc)\n",
    "                return -np.sum(p * np.log(p + 1e-10))\n",
    "            \n",
    "            # Calculate TE components\n",
    "            h_y_fut_y_past = joint_entropy(y_fut_disc, y_past_disc)\n",
    "            h_x_past_y_past = joint_entropy(x_past_disc, y_past_disc)\n",
    "            h_y_past = entropy(np.bincount(y_past_disc) / len(y_past_disc) + 1e-10)\n",
    "            h_y_fut_x_past_y_past = triple_entropy(y_fut_disc, x_past_disc, y_past_disc)\n",
    "            \n",
    "            te = h_y_fut_y_past + h_x_past_y_past - h_y_fut_x_past_y_past - h_y_past\n",
    "            return max(0, te)\n",
    "            \n",
    "        except:\n",
    "            return 0.0\n",
    "    \n",
    "    def entropy_rate_sequence(self, frame_indices, window_size=5, spatial_region=None):\n",
    "        \"\"\"\n",
    "        Calculate entropy rate for a sequence of frames\n",
    "        \"\"\"\n",
    "        if len(frame_indices) < window_size + 1:\n",
    "            return []\n",
    "        \n",
    "        # Extract time series\n",
    "        time_series = []\n",
    "        for frame_idx in frame_indices:\n",
    "            field = self.archive.read_frame(frame_idx)\n",
    "            stress = self.get_stress(field)\n",
    "            \n",
    "            if spatial_region is not None:\n",
    "                y_slice, x_slice = spatial_region\n",
    "                stress_val = np.mean(stress[y_slice, x_slice])\n",
    "            else:\n",
    "                stress_val = np.mean(stress)\n",
    "            \n",
    "            time_series.append(stress_val)\n",
    "        \n",
    "        time_series = np.array(time_series)\n",
    "        \n",
    "        # Calculate entropy rate\n",
    "        rates = []\n",
    "        for i in range(window_size, len(time_series)):\n",
    "            # Current entropy\n",
    "            current_val = time_series[i]\n",
    "            current_entropy = -np.log(1.0 + abs(current_val) + 1e-10)  # Simplified\n",
    "            \n",
    "            # Past window entropy\n",
    "            past_window = time_series[i-window_size:i]\n",
    "            past_entropy = np.mean([-np.log(1.0 + abs(val) + 1e-10) for val in past_window])\n",
    "            \n",
    "            # Rate = new entropy - predictable entropy\n",
    "            rate = current_entropy - 0.7 * past_entropy\n",
    "            rates.append(max(0, rate))\n",
    "        \n",
    "        return np.array(rates)\n",
    "    \n",
    "    def information_flow_field_frames(self, frame1_idx, frame2_idx, spatial_window=3):\n",
    "        \"\"\"\n",
    "        Calculate information flow field between two frames\n",
    "        \"\"\"\n",
    "        field1 = self.archive.read_frame(frame1_idx)\n",
    "        field2 = self.archive.read_frame(frame2_idx)\n",
    "        \n",
    "        stress1 = self.get_stress(field1)\n",
    "        stress2 = self.get_stress(field2)\n",
    "        \n",
    "        ny, nx = stress1.shape\n",
    "        flow_field = np.zeros((ny-2*spatial_window, nx-2*spatial_window))\n",
    "        \n",
    "        for i in range(spatial_window, ny-spatial_window):\n",
    "            for j in range(spatial_window, nx-spatial_window):\n",
    "                # Extract local region\n",
    "                region1 = stress1[i-spatial_window:i+spatial_window+1, \n",
    "                                j-spatial_window:j+spatial_window+1]\n",
    "                region2 = stress2[i-spatial_window:i+spatial_window+1, \n",
    "                                j-spatial_window:j+spatial_window+1]\n",
    "                \n",
    "                # Calculate local MI\n",
    "                local_mi = self.mutual_info_corrected(region1.ravel(), region2.ravel())\n",
    "                flow_field[i-spatial_window, j-spatial_window] = local_mi\n",
    "        \n",
    "        return flow_field\n",
    "    \n",
    "    def analyze_complete_archive(self, N, max_delta=30, spatial_regions=None):\n",
    "        \"\"\"\n",
    "        Complete analysis of your archive data\n",
    "        \"\"\"\n",
    "        print(\"=== COMPLETE ARCHIVE INFORMATION ANALYSIS ===\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # 1. Improved MI over deltas\n",
    "        print(\"\\n1. Computing improved MI over deltas...\")\n",
    "        mi_results = self.measure_MI_over_deltas_improved(N, max_delta)\n",
    "        results['mi_analysis'] = mi_results\n",
    "        \n",
    "        # 2. Transfer entropy for representative frame sequences\n",
    "        print(\"\\n2. Computing transfer entropy...\")\n",
    "        te_results = []\n",
    "        for start_frame in range(0, N-20, 20):  # Every 20 frames\n",
    "            frame_seq = list(range(start_frame, min(start_frame+15, N)))\n",
    "            te = self.transfer_entropy_frame_sequence(frame_seq)\n",
    "            te_results.append(te)\n",
    "        results['transfer_entropy'] = np.array(te_results)\n",
    "        \n",
    "        # 3. Entropy rate\n",
    "        print(\"\\n3. Computing entropy rate...\")\n",
    "        entropy_rates = []\n",
    "        for start_frame in range(0, N-10, 10):\n",
    "            frame_seq = list(range(start_frame, min(start_frame+10, N)))\n",
    "            rates = self.entropy_rate_sequence(frame_seq)\n",
    "            if len(rates) > 0:\n",
    "                entropy_rates.extend(rates)\n",
    "        results['entropy_rates'] = np.array(entropy_rates)\n",
    "        \n",
    "        # 4. Information flow fields (sample frames)\n",
    "        print(\"\\n4. Computing information flow fields...\")\n",
    "        sample_frames = [0, N//4, N//2, 3*N//4, N-2]\n",
    "        flow_fields = {}\n",
    "        for i, frame in enumerate(sample_frames[:-1]):\n",
    "            if frame+1 < N:\n",
    "                flow_field = self.information_flow_field_frames(frame, frame+1)\n",
    "                flow_fields[f'{frame}->{frame+1}'] = flow_field\n",
    "        results['flow_fields'] = flow_fields\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def plot_comprehensive_analysis(self, results):\n",
    "        \"\"\"\n",
    "        Plot comprehensive analysis results\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "        \n",
    "        # 1. MI over deltas - different spatial lags\n",
    "        ax = axes[0, 0]\n",
    "        mi_data = results['mi_analysis']\n",
    "        for lag in [(0,0), (1,0), (0,1)]:\n",
    "            if lag in mi_data['spatial_mi_stats']:\n",
    "                ax.plot(mi_data['time_deltas'], \n",
    "                       mi_data['spatial_mi_stats'][lag]['mean'], \n",
    "                       label=f'Spatial lag {lag}', linewidth=2)\n",
    "        ax.set_title('MI vs Time Delta (Spatial Lags)')\n",
    "        ax.set_xlabel('Time Delta')\n",
    "        ax.set_ylabel('Mutual Information')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        \n",
    "        # 2. Total MI mean and variance\n",
    "        ax = axes[0, 1]\n",
    "        ax.plot(mi_data['time_deltas'], mi_data['total_mi_mean'], 'b-', linewidth=2, label='Mean')\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.plot(mi_data['time_deltas'], mi_data['total_mi_var'], 'r--', linewidth=2, label='Variance')\n",
    "        ax.set_xlabel('Time Delta')\n",
    "        ax.set_ylabel('Total MI Mean', color='b')\n",
    "        ax2.set_ylabel('Total MI Variance', color='r')\n",
    "        ax.set_title('Total MI Statistics')\n",
    "        ax.grid(True)\n",
    "        \n",
    "        # 3. Transfer entropy\n",
    "        ax = axes[0, 2]\n",
    "        if len(results['transfer_entropy']) > 0:\n",
    "            ax.plot(results['transfer_entropy'], 'g-', linewidth=2)\n",
    "        ax.set_title('Transfer Entropy Evolution')\n",
    "        ax.set_xlabel('Frame Sequence')\n",
    "        ax.set_ylabel('Transfer Entropy')\n",
    "        ax.grid(True)\n",
    "        \n",
    "        # 4. Entropy rates\n",
    "        ax = axes[1, 0]\n",
    "        if len(results['entropy_rates']) > 0:\n",
    "            ax.plot(results['entropy_rates'], 'purple', linewidth=2)\n",
    "        ax.set_title('Information Generation Rate')\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel('Entropy Rate')\n",
    "        ax.grid(True)\n",
    "        \n",
    "        # 5-7. Information flow fields\n",
    "        flow_fields = results['flow_fields']\n",
    "        field_keys = list(flow_fields.keys())\n",
    "        \n",
    "        for i, key in enumerate(field_keys[:3]):\n",
    "            if i < 3:\n",
    "                ax = axes[1, 1+i] if i < 2 else axes[2, 0]\n",
    "                im = ax.imshow(flow_fields[key], cmap='plasma', aspect='auto')\n",
    "                ax.set_title(f'Info Flow: {key}')\n",
    "                plt.colorbar(im, ax=ax)\n",
    "        \n",
    "        # 8. MI correlation analysis\n",
    "        ax = axes[2, 1]\n",
    "        # Plot correlation between different spatial lags\n",
    "        if (0,0) in mi_data['spatial_mi_stats'] and (1,0) in mi_data['spatial_mi_stats']:\n",
    "            direct_mi = mi_data['spatial_mi_stats'][(0,0)]['mean']\n",
    "            spatial_mi = mi_data['spatial_mi_stats'][(1,0)]['mean']\n",
    "            ax.scatter(direct_mi, spatial_mi, alpha=0.6)\n",
    "            ax.set_xlabel('Direct MI')\n",
    "            ax.set_ylabel('Spatial Lag MI')\n",
    "            ax.set_title('MI Correlation Analysis')\n",
    "            ax.grid(True)\n",
    "        \n",
    "        # 9. Summary statistics\n",
    "        ax = axes[2, 2]\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Summary text\n",
    "        summary_text = \"ANALYSIS SUMMARY\\n\\n\"\n",
    "        summary_text += f\"Max MI: {max(mi_data['total_mi_mean']):.3f}\\n\"\n",
    "        summary_text += f\"Avg MI: {np.mean(mi_data['total_mi_mean']):.3f}\\n\"\n",
    "        if len(results['transfer_entropy']) > 0:\n",
    "            summary_text += f\"Avg TE: {np.mean(results['transfer_entropy']):.3f}\\n\"\n",
    "        if len(results['entropy_rates']) > 0:\n",
    "            summary_text += f\"Avg Entropy Rate: {np.mean(results['entropy_rates']):.3f}\\n\"\n",
    "        \n",
    "        ax.text(0.1, 0.9, summary_text, transform=ax.transAxes, fontsize=12,\n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightgray'))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage that matches your format:\n",
    "\"\"\"\n",
    "# Assuming you have:\n",
    "# - ar: your archive object\n",
    "# - get_isotropic_stress: your stress extraction function\n",
    "# - N: number of frames to analyze\n",
    "\n",
    "# Create analyzer\n",
    "analyzer = ImprovedInfoAnalyzer(ar, get_isotropic_stress)\n",
    "\n",
    "# Run complete analysis\n",
    "results = analyzer.analyze_complete_archive(N=121, max_delta=50)\n",
    "\n",
    "# Plot results\n",
    "analyzer.plot_comprehensive_analysis(results)\n",
    "\n",
    "# Access specific results:\n",
    "# results['mi_analysis'] - improved MI analysis\n",
    "# results['transfer_entropy'] - transfer entropy values\n",
    "# results['entropy_rates'] - entropy rate evolution\n",
    "# results['flow_fields'] - spatial information flow fields\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
